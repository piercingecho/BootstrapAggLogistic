{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96dae9a3",
   "metadata": {},
   "source": [
    "# Final Project - Logistic Regression Bagging for Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104c584",
   "metadata": {},
   "source": [
    "We hope to compare the metrics of our algorithm of bagging logistic models, as opposed to the metrics of sklearn's logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c5fea3",
   "metadata": {},
   "source": [
    "### What is \"Logistic Bagging?\"\n",
    "\n",
    "Logistic Bagging, as this notebook implements, is a form of bootstrap aggregation. Bootstrap aggregation is the claim that we can take a goup of machine learning algorithms, each of which weakly learn our data, and then combine them to become greater than the sum of its parts. These 'weak learners' each learn the data slightly better than chance, but the overall learning algorithm sometimes performs quite well. This bagging is seen with neural nets and random decision forests, as decision trees or perceptrons often overfit the data or assume linear separability respectively.\n",
    "\n",
    "Logistic bagging is a method of this that creates multiple logistic regression models for a given dataset. Each of these logistic regression models are used to 'vote' on the classification of a particular instance's class label. The plurality vote is the class label that is assigned to that instance. As we go forward, we will implement this ML model and compare its results to logistic regression on a dataset of dry beans, procured from [a zip file in this archive](https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff245c92",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "\n",
    "Random is utilized for the bagging method, which implements some form of chance in how these bags are generated.\n",
    "\n",
    "Pandas is helpful for dataframe manipulation.\n",
    "\n",
    "Numpy helps with array manipulation.\n",
    "\n",
    "Sklearn is a beneficial library with various machine learning algorithms, including the logistic regression model that we compare our model with. It is also able to take a set of predictions and create various metrics with it, notably a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b95165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn utility\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sklearn classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sklearn grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# sklearn metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda84ab2",
   "metadata": {},
   "source": [
    "To ensure replicability of our code, we would like to have the random library to be seeded, which we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dccb05b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe5cb01",
   "metadata": {},
   "source": [
    "Below is a group of helper functions to create what is referred to as a \"bag.\" These are important for our purposes because these groups of a subset of instances/features is what makes a single logistic model a 'weak learner.' It is only trained on a subset of the entire data set, so this is how we create that subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632e3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random bagging:\n",
    "# shuffle a list of indices.\n",
    "# Take the first numInstances items in the list.\n",
    "# Create a dictionary, representing which rows are in the new list.\n",
    "# From that dictionary, create a pandas series. Then we can create a filtered dataframe.\n",
    "\n",
    "# Time complexity: n^2, because of d[i] = i in chosenInstances\n",
    "\n",
    "def bagBooleans(array, m):\n",
    "    # returns a pd series of booleans with m true values from n total elements.\n",
    "    \n",
    "    random.shuffle(array)\n",
    "    \n",
    "    chosenInstances = array[:m]\n",
    "    \n",
    "    # Create a pandas series of size n, to store booleans of which rows\n",
    "    # we keep for a given logistic model.\n",
    "    d = {}\n",
    "    for i in array:\n",
    "        d[i] = i in chosenInstances\n",
    "    bagBooleans = pd.Series(data=d, index = array.copy())\n",
    "    return bagBooleans\n",
    "\n",
    "def createBag(dataframe, numInstances = 10, numFeatures = 3, random_state = -1):\n",
    "    # random?\n",
    "    '''\n",
    "    if(random_state != -1):\n",
    "        random.seed(random_state)\n",
    "    '''\n",
    "        \n",
    "    numRows = dataframe.shape[0]\n",
    "    numCols = dataframe.shape[1]\n",
    "    \n",
    "    # bagging for columns\n",
    "    \n",
    "    chosen_cols = bagBooleans(list(i for i in range(dataframe.shape[1])), numFeatures)\n",
    "    chosen_cols_names = dataframe.columns[chosen_cols].values\n",
    "    df_bagged_columns = dataframe.loc[:,chosen_cols_names]\n",
    "    \n",
    "    # bagging for rows\n",
    "    chosen_rows = bagBooleans(list(dataframe.index), numInstances)\n",
    "    bag = df_bagged_columns[list(chosen_rows)]\n",
    " \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0d660",
   "metadata": {},
   "source": [
    "Below is the class we use to manipulated the logistic bagging ML model. It is based on sklearn's objects for ML models, so that its usage syntax is consistent. Most notably, the model has attributes to be able to fit onto a training set, and then predict on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b173c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the absolute minimum for something like this is the ability to fit the model, and then the ability to predict with it.\n",
    "\n",
    "class AggregatedLogistic:\n",
    "    def __init__(self):\n",
    "        self.isFit = False\n",
    "        self.models = []\n",
    "        self.model_cols = []\n",
    "    \n",
    "    def fit(self, x_train, y_train, n_estimators = 5, solver='lbfgs',\n",
    "                            multi_class='multinomial',\n",
    "                            C=1e-2,\n",
    "                            random_state = 42):\n",
    "        # random state? \n",
    "        \n",
    "        self.isFit = True\n",
    "        \n",
    "        # make number of models\n",
    "        for i in range(n_estimators):\n",
    "            # split the data randomly\n",
    "            bag_num_instances = int(x_train.shape[0] / n_estimators)\n",
    "            bag_num_predictors = random.randint(2,x_train.shape[1])\n",
    "            \n",
    "            bag = createBag(x_train, \n",
    "                            bag_num_instances,\n",
    "                            bag_num_predictors,\n",
    "                            random_state=random_state)\n",
    "            # then fit a logreg to the bag that was created\n",
    "            \n",
    "            model = LogisticRegression(solver = solver,\n",
    "                                   multi_class=multi_class,\n",
    "                                    C=C,\n",
    "                                    random_state=random_state)\n",
    "            x_fit = bag\n",
    "            y_fit = y_train.loc[list(bag.index)]\n",
    "            \n",
    "            model.fit(x_fit, y_fit)\n",
    "            self.models.append(model)\n",
    "            self.model_cols.append(bag.columns)\n",
    "            \n",
    "    def predict(self, x_test):\n",
    "        #make the series go boom and plurality vote winner gets it\n",
    "        if(not self.isFit):\n",
    "            print(\"Model not yet fit to a data set.\")\n",
    "            return\n",
    "        predictions = np.ndarray(shape=(1, len(x_test)), dtype=object, order='F')\n",
    "        \n",
    "        model_preds = []\n",
    "        \n",
    "        for i in range(len(self.models)):\n",
    "            test_data = (x_test[self.model_cols[i]])\n",
    "            curr_preds = self.models[i].predict(test_data)\n",
    "            model_preds.append(curr_preds)\n",
    "        \n",
    "        for i in range(predictions.shape[1]):\n",
    "            array_predictions = []\n",
    "            unique_preds = []\n",
    "            for pred in model_preds:\n",
    "                array_predictions.append(pred[i])\n",
    "                if(not(pred[i] in unique_preds)):\n",
    "                    unique_preds.append(pred[i])\n",
    "            unique_preds = sorted(unique_preds, key = lambda x:array_predictions.count(x), reverse=True)\n",
    "            predictions[0, i] = unique_preds[0]\n",
    "        \n",
    "        return predictions[0]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951a808",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2541f2d",
   "metadata": {},
   "source": [
    "The zip file has a messy data set, so we instead use a data set that was cleaned from previous data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53bec2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRatio</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28395</td>\n",
       "      <td>610.291</td>\n",
       "      <td>208.178117</td>\n",
       "      <td>173.888747</td>\n",
       "      <td>1.197191</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.141097</td>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28734</td>\n",
       "      <td>638.018</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.272750</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29380</td>\n",
       "      <td>624.110</td>\n",
       "      <td>212.826130</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30008</td>\n",
       "      <td>645.884</td>\n",
       "      <td>210.557999</td>\n",
       "      <td>182.516516</td>\n",
       "      <td>1.153638</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.467062</td>\n",
       "      <td>0.782681</td>\n",
       "      <td>0.976696</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30140</td>\n",
       "      <td>620.134</td>\n",
       "      <td>201.847882</td>\n",
       "      <td>190.279279</td>\n",
       "      <td>1.060798</td>\n",
       "      <td>0.333680</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.896503</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Area  Perimeter  MajorAxisLength  MinorAxisLength  \\\n",
       "0           0  28395    610.291       208.178117       173.888747   \n",
       "1           1  28734    638.018       200.524796       182.734419   \n",
       "2           2  29380    624.110       212.826130       175.931143   \n",
       "3           3  30008    645.884       210.557999       182.516516   \n",
       "4           4  30140    620.134       201.847882       190.279279   \n",
       "\n",
       "   AspectRatio  Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  \\\n",
       "0     1.197191      0.549812       28715     190.141097  0.763923  0.988856   \n",
       "1     1.097356      0.411785       29172     191.272750  0.783968  0.984986   \n",
       "2     1.209713      0.562727       29690     193.410904  0.778113  0.989559   \n",
       "3     1.153638      0.498616       30724     195.467062  0.782681  0.976696   \n",
       "4     1.060798      0.333680       30417     195.896503  0.773098  0.990893   \n",
       "\n",
       "   Roundness  Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  \\\n",
       "0   0.958027     0.913358      0.007332      0.003147      0.834222   \n",
       "1   0.887034     0.953861      0.006979      0.003564      0.909851   \n",
       "2   0.947849     0.908774      0.007244      0.003048      0.825871   \n",
       "3   0.903936     0.928329      0.007017      0.003215      0.861794   \n",
       "4   0.984877     0.970516      0.006697      0.003665      0.941900   \n",
       "\n",
       "   ShapeFactor4  Class  \n",
       "0      0.998724  SEKER  \n",
       "1      0.998430  SEKER  \n",
       "2      0.999066  SEKER  \n",
       "3      0.994199  SEKER  \n",
       "4      0.999166  SEKER  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Clean_Bean_Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa7e62",
   "metadata": {},
   "source": [
    "We have to drop a column that was included when saving the data set, but afterwards the data is cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17daa36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRatio</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28395</td>\n",
       "      <td>610.291</td>\n",
       "      <td>208.178117</td>\n",
       "      <td>173.888747</td>\n",
       "      <td>1.197191</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.141097</td>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28734</td>\n",
       "      <td>638.018</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.272750</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29380</td>\n",
       "      <td>624.110</td>\n",
       "      <td>212.826130</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30008</td>\n",
       "      <td>645.884</td>\n",
       "      <td>210.557999</td>\n",
       "      <td>182.516516</td>\n",
       "      <td>1.153638</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.467062</td>\n",
       "      <td>0.782681</td>\n",
       "      <td>0.976696</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30140</td>\n",
       "      <td>620.134</td>\n",
       "      <td>201.847882</td>\n",
       "      <td>190.279279</td>\n",
       "      <td>1.060798</td>\n",
       "      <td>0.333680</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.896503</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n",
       "0  28395    610.291       208.178117       173.888747     1.197191   \n",
       "1  28734    638.018       200.524796       182.734419     1.097356   \n",
       "2  29380    624.110       212.826130       175.931143     1.209713   \n",
       "3  30008    645.884       210.557999       182.516516     1.153638   \n",
       "4  30140    620.134       201.847882       190.279279     1.060798   \n",
       "\n",
       "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n",
       "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
       "1      0.411785       29172     191.272750  0.783968  0.984986   0.887034   \n",
       "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
       "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
       "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
       "\n",
       "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
       "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
       "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
       "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
       "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
       "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff7792",
   "metadata": {},
   "source": [
    "Below, we show a test of creating a bag. We create one with ten instances and three features, which is just a subset of the overall dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca5684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "    Area  Perimeter  MajorAxisLength\n",
      "0  28395    610.291       208.178117\n",
      "1  28734    638.018       200.524796\n",
      "2  29380    624.110       212.826130\n",
      "3  30008    645.884       210.557999\n",
      "4  30140    620.134       201.847882\n",
      "5  30279    634.927       212.560556\n",
      "6  30477    670.033       211.050155\n",
      "7  30519    629.727       212.996755\n",
      "8  30685    635.681       213.534145\n",
      "9  30834    631.934       217.227813\n"
     ]
    }
   ],
   "source": [
    "sample_bag = createBag(df, numInstances = 10, numFeatures = 3, random_state=44)\n",
    "print(type(sample_bag))\n",
    "print(sample_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da826dc0",
   "metadata": {},
   "source": [
    "### Splitting/Scaling our Data\n",
    "\n",
    "To show a test of the aggregatedLogistic class, we must be able to create instances of a logistic model as well. To do that, we must split and scale the data for model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3fdb57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRatio</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>91751</td>\n",
       "      <td>1146.703</td>\n",
       "      <td>445.176120</td>\n",
       "      <td>264.370534</td>\n",
       "      <td>1.683910</td>\n",
       "      <td>0.804571</td>\n",
       "      <td>92725</td>\n",
       "      <td>341.790874</td>\n",
       "      <td>0.670871</td>\n",
       "      <td>0.989496</td>\n",
       "      <td>0.876837</td>\n",
       "      <td>0.767766</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.589464</td>\n",
       "      <td>0.992604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>87979</td>\n",
       "      <td>1148.631</td>\n",
       "      <td>443.738692</td>\n",
       "      <td>255.653953</td>\n",
       "      <td>1.735700</td>\n",
       "      <td>0.817354</td>\n",
       "      <td>89768</td>\n",
       "      <td>334.691413</td>\n",
       "      <td>0.692835</td>\n",
       "      <td>0.980071</td>\n",
       "      <td>0.837969</td>\n",
       "      <td>0.754253</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.568898</td>\n",
       "      <td>0.987437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8100</th>\n",
       "      <td>42001</td>\n",
       "      <td>768.513</td>\n",
       "      <td>285.177858</td>\n",
       "      <td>188.821847</td>\n",
       "      <td>1.510301</td>\n",
       "      <td>0.749398</td>\n",
       "      <td>42528</td>\n",
       "      <td>231.251668</td>\n",
       "      <td>0.772304</td>\n",
       "      <td>0.987608</td>\n",
       "      <td>0.893649</td>\n",
       "      <td>0.810903</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.657564</td>\n",
       "      <td>0.993120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>54677</td>\n",
       "      <td>911.022</td>\n",
       "      <td>308.853903</td>\n",
       "      <td>226.398571</td>\n",
       "      <td>1.364204</td>\n",
       "      <td>0.680198</td>\n",
       "      <td>55858</td>\n",
       "      <td>263.850182</td>\n",
       "      <td>0.753013</td>\n",
       "      <td>0.978857</td>\n",
       "      <td>0.827860</td>\n",
       "      <td>0.854288</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.729808</td>\n",
       "      <td>0.995607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6015</th>\n",
       "      <td>49573</td>\n",
       "      <td>880.556</td>\n",
       "      <td>350.312735</td>\n",
       "      <td>181.419348</td>\n",
       "      <td>1.930956</td>\n",
       "      <td>0.855454</td>\n",
       "      <td>50084</td>\n",
       "      <td>251.233565</td>\n",
       "      <td>0.617025</td>\n",
       "      <td>0.989797</td>\n",
       "      <td>0.803417</td>\n",
       "      <td>0.717169</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.514332</td>\n",
       "      <td>0.993152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n",
       "5412  91751   1146.703       445.176120       264.370534     1.683910   \n",
       "5347  87979   1148.631       443.738692       255.653953     1.735700   \n",
       "8100  42001    768.513       285.177858       188.821847     1.510301   \n",
       "2118  54677    911.022       308.853903       226.398571     1.364204   \n",
       "6015  49573    880.556       350.312735       181.419348     1.930956   \n",
       "\n",
       "      Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n",
       "5412      0.804571       92725     341.790874  0.670871  0.989496   0.876837   \n",
       "5347      0.817354       89768     334.691413  0.692835  0.980071   0.837969   \n",
       "8100      0.749398       42528     231.251668  0.772304  0.987608   0.893649   \n",
       "2118      0.680198       55858     263.850182  0.753013  0.978857   0.827860   \n",
       "6015      0.855454       50084     251.233565  0.617025  0.989797   0.803417   \n",
       "\n",
       "      Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n",
       "5412     0.767766      0.004852      0.001040      0.589464      0.992604  \n",
       "5347     0.754253      0.005044      0.001007      0.568898      0.987437  \n",
       "8100     0.810903      0.006790      0.001811      0.657564      0.993120  \n",
       "2118     0.854288      0.005649      0.001856      0.729808      0.995607  \n",
       "6015     0.717169      0.007067      0.001153      0.514332      0.993152  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df, df['Class'], test_size=0.2, random_state=45, stratify=df[['Class']])\n",
    "x_train = x_train.drop('Class', axis=1)\n",
    "x_test = x_test.drop('Class', axis=1)\n",
    "x_train.shape[0], x_test.shape[0]\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb05996d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRatio</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>1.322486</td>\n",
       "      <td>1.364378</td>\n",
       "      <td>1.465726</td>\n",
       "      <td>1.380619</td>\n",
       "      <td>0.419032</td>\n",
       "      <td>0.590841</td>\n",
       "      <td>1.311021</td>\n",
       "      <td>1.502853</td>\n",
       "      <td>-1.613505</td>\n",
       "      <td>0.504278</td>\n",
       "      <td>0.056924</td>\n",
       "      <td>-0.530370</td>\n",
       "      <td>-1.517329</td>\n",
       "      <td>-1.142718</td>\n",
       "      <td>-0.556561</td>\n",
       "      <td>-0.564727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>1.193825</td>\n",
       "      <td>1.373383</td>\n",
       "      <td>1.448936</td>\n",
       "      <td>1.186784</td>\n",
       "      <td>0.629594</td>\n",
       "      <td>0.729453</td>\n",
       "      <td>1.211687</td>\n",
       "      <td>1.382829</td>\n",
       "      <td>-1.164776</td>\n",
       "      <td>-1.508755</td>\n",
       "      <td>-0.596795</td>\n",
       "      <td>-0.749669</td>\n",
       "      <td>-1.347338</td>\n",
       "      <td>-1.198191</td>\n",
       "      <td>-0.764506</td>\n",
       "      <td>-1.749044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8100</th>\n",
       "      <td>-0.374463</td>\n",
       "      <td>-0.402155</td>\n",
       "      <td>-0.403078</td>\n",
       "      <td>-0.299400</td>\n",
       "      <td>-0.286795</td>\n",
       "      <td>-0.007456</td>\n",
       "      <td>-0.375247</td>\n",
       "      <td>-0.365922</td>\n",
       "      <td>0.458767</td>\n",
       "      <td>0.101103</td>\n",
       "      <td>0.339689</td>\n",
       "      <td>0.169745</td>\n",
       "      <td>0.201142</td>\n",
       "      <td>0.152109</td>\n",
       "      <td>0.132017</td>\n",
       "      <td>-0.446469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>0.057910</td>\n",
       "      <td>0.263507</td>\n",
       "      <td>-0.126538</td>\n",
       "      <td>0.536215</td>\n",
       "      <td>-0.880770</td>\n",
       "      <td>-0.757858</td>\n",
       "      <td>0.072548</td>\n",
       "      <td>0.185188</td>\n",
       "      <td>0.064639</td>\n",
       "      <td>-1.767993</td>\n",
       "      <td>-0.766816</td>\n",
       "      <td>0.873867</td>\n",
       "      <td>-0.810802</td>\n",
       "      <td>0.227491</td>\n",
       "      <td>0.862491</td>\n",
       "      <td>0.123609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6015</th>\n",
       "      <td>-0.116185</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.357707</td>\n",
       "      <td>-0.464014</td>\n",
       "      <td>1.423428</td>\n",
       "      <td>1.142616</td>\n",
       "      <td>-0.121418</td>\n",
       "      <td>-0.028108</td>\n",
       "      <td>-2.713578</td>\n",
       "      <td>0.568636</td>\n",
       "      <td>-1.177915</td>\n",
       "      <td>-1.351533</td>\n",
       "      <td>0.446628</td>\n",
       "      <td>-0.952661</td>\n",
       "      <td>-1.316238</td>\n",
       "      <td>-0.439086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n",
       "5412  1.322486   1.364378         1.465726         1.380619     0.419032   \n",
       "5347  1.193825   1.373383         1.448936         1.186784     0.629594   \n",
       "8100 -0.374463  -0.402155        -0.403078        -0.299400    -0.286795   \n",
       "2118  0.057910   0.263507        -0.126538         0.536215    -0.880770   \n",
       "6015 -0.116185   0.121200         0.357707        -0.464014     1.423428   \n",
       "\n",
       "      Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n",
       "5412      0.590841    1.311021       1.502853 -1.613505  0.504278   0.056924   \n",
       "5347      0.729453    1.211687       1.382829 -1.164776 -1.508755  -0.596795   \n",
       "8100     -0.007456   -0.375247      -0.365922  0.458767  0.101103   0.339689   \n",
       "2118     -0.757858    0.072548       0.185188  0.064639 -1.767993  -0.766816   \n",
       "6015      1.142616   -0.121418      -0.028108 -2.713578  0.568636  -1.177915   \n",
       "\n",
       "      Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n",
       "5412    -0.530370     -1.517329     -1.142718     -0.556561     -0.564727  \n",
       "5347    -0.749669     -1.347338     -1.198191     -0.764506     -1.749044  \n",
       "8100     0.169745      0.201142      0.152109      0.132017     -0.446469  \n",
       "2118     0.873867     -0.810802      0.227491      0.862491      0.123609  \n",
       "6015    -1.351533      0.446628     -0.952661     -1.316238     -0.439086  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: index = x_train.index or index = x_test.index. these MUST be maintained to align\n",
    "# with y_train. \n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns = x_train.columns, index = x_train.index)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns = x_test.columns, index = x_test.index)\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d934b0",
   "metadata": {},
   "source": [
    "### Comparing Logistic Regression to Logistic Bagging\n",
    "\n",
    "We create a logistic regression model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcc06d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.94      0.86      0.90       265\n",
      "      BOMBAY       1.00      1.00      1.00       104\n",
      "        CALI       0.90      0.94      0.92       326\n",
      "    DERMASON       0.91      0.92      0.91       709\n",
      "       HOROZ       0.94      0.95      0.94       372\n",
      "       SEKER       0.95      0.92      0.93       406\n",
      "        SIRA       0.83      0.86      0.84       527\n",
      "\n",
      "    accuracy                           0.91      2709\n",
      "   macro avg       0.92      0.92      0.92      2709\n",
      "weighted avg       0.91      0.91      0.91      2709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs',\n",
    "                            multi_class='multinomial',\n",
    "                            C=1e-2,\n",
    "                            random_state = 0)\n",
    "logreg.fit(x_train, y_train)\n",
    "logreg_report = classification_report(y_test, logreg.predict(x_test))\n",
    "print(logreg_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9629aa",
   "metadata": {},
   "source": [
    "From the above data, we can see that a standard logistic regression ML algorithm learns this data fairly effectively, with an accuracy score of 91%. So this test will not be about whether it finds something completely new, but rather if this algorithm can maintain a similar effectiveness. Now, let's compare it with our aggregated logistic regression ML algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0ef070e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.95      0.75      0.84       265\n",
      "      BOMBAY       1.00      1.00      1.00       104\n",
      "        CALI       0.86      0.94      0.90       326\n",
      "    DERMASON       0.85      0.95      0.89       709\n",
      "       HOROZ       0.94      0.95      0.94       372\n",
      "       SEKER       0.95      0.89      0.92       406\n",
      "        SIRA       0.83      0.78      0.80       527\n",
      "\n",
      "    accuracy                           0.89      2709\n",
      "   macro avg       0.91      0.89      0.90      2709\n",
      "weighted avg       0.89      0.89      0.89      2709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agglog = AggregatedLogistic()\n",
    "agglog.fit(x_train, y_train, solver='lbfgs',\n",
    "                            multi_class='multinomial',\n",
    "                            C=1e-2,\n",
    "                            random_state = 0,\n",
    "                            n_estimators = 5)\n",
    "agglog_report = classification_report(y_test, agglog.predict(x_test))\n",
    "print(agglog_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e4bcc",
   "metadata": {},
   "source": [
    "## Discussion and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a735395",
   "metadata": {},
   "source": [
    "The above report gives an accuracy score of 87%, which is comparable to a pure logistic standpoint. Somewhat surprisingly, it also fully separated Bombay from the other class labels. This is notable particularly because not every weak learner will have the needed information to be able to sully separate Bombay.\n",
    "\n",
    "The primary thing to note with this learner is what happens in repeated executions: by running the above cell repeatedly, you will notice that the f1-scores and accuracy scores vary drastically. The major drawback of the random bagging method we perform is that it is random, and therefore, the models we create are quite subject to random chance. We have no guarantee (in fact, it is almost impossible) that every instance will be used in creating the models, and there is a possibility that due to random chance some features will be considered in many more models than others.\n",
    "\n",
    "Additionally, random bagging for logistic regression maintains many of the flaws of a logistic model -- data sets that aren't linearly separable can still be difficult to fit effectively, as unlike decision forests we aren't trying to overfit smaller parts of our data. Further, this method is much more difficult to explain to someone who may be seeking an accessible machine learning algorithm, as per Occam's Razor.\n",
    "\n",
    "The development of this algorithm has been an insightful survey into bagging methods more generally, and it is promising that this maintains most of the effectiveness of a logistic model. Due to random variance of the model and difficulty to explain, recommending it as an alternative to longer-standing models is contentious. However, bagging models in general have been quite promising for further study, for algorithms such as random decision forests use an extremely similar bagging method to create models that have seen much success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333d915",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "Thanks to the professor for everything in the course and in working to achieve this implementation. Thanks to a classmate for reminding me of loc versus iloc in pandas, which took way too much time to debug.\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.html\n",
    "- https://stackoverflow.com/questions/11285613/selecting-multiple-columns-in-a-pandas-dataframe\n",
    "- https://pandas.pydata.org/docs/reference/indexing.html\n",
    "- https://pandas.pydata.org/docs/user_guide/indexing.html\n",
    "- https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Int64Index.html\n",
    "\n",
    "- honorable mention to this exact problem i was having in stackoverflow like ten years ago https://stackoverflow.com/questions/52428472/typeerror-unhashable-type-list-when-calling-iloc\n",
    "\n",
    "- https://stackoverflow.com/questions/35723472/how-to-use-sklearn-fit-transform-with-pandas-and-return-dataframe-instead-of-num\n",
    "- https://stackoverflow.com/questions/46628837/fit-got-an-unexpected-keyword-argument-criterion\n",
    "- https://towardsdatascience.com/indexing-best-practices-in-pandas-series-e455c7d2417\n",
    "- https://www.sharpsightlabs.com/blog/sklearn-predict/\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f4471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
